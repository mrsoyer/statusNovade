# Rapport de Suivi du Projet Novade

*Mise √† jour du 16 d√©cembre 2024*

---

## Introduction

Ce rapport pr√©sente l'√©tat actuel du projet Novade, qui vise √† migrer notre infrastructure technique vers une nouvelle architecture. L'objectif principal est de centraliser et de traiter les donn√©es provenant de diverses sources telles que Salesforce, Drift, et le plan de tracking, afin d'am√©liorer le stockage et l'analyse des donn√©es dans un environnement Databricks/Azure/Amplitude.

![Plan Novade](https://i.ibb.co/TYYdjMp/Capture-d-e-cran-2024-12-16-a-13-21-23.png)

### Points Cl√©s et KPIs

- **Dur√©e du Projet** : √Ä ce jour, 16 jours de travail ont √©t√© consacr√©s sur les 24 jours pr√©vus, soit 80% du temps allou√©.
- **Progr√®s R√©alis√©s** : La majorit√© des scripts de migration et d'int√©gration sont en place, avec des tests en cours pour assurer la stabilit√© et la performance.
- **D√©fis Majeurs** : Adaptation des workflows Databricks pour des automatisations complexes, et gestion des autorisations avec Amplitude, Azure, et Salesforce.
- **Solutions Envisag√©es** : Migration vers des solutions plus flexibles comme Azure Blob Storage et Synapse Analytics pour une meilleure gestion des donn√©es.

Ce document est con√ßu pour fournir une vue d'ensemble claire et accessible des progr√®s r√©alis√©s, des d√©fis rencontr√©s et des solutions envisag√©es. Nous restons engag√©s √† travailler en √©troite collaboration avec toutes les parties prenantes pour assurer le succ√®s de cette migration.

---

## üìä Pr√©sentation du Projet

Le projet Novade consiste en la migration d'une solution √©prouv√©e (n8n/Segment/BigQuery) vers une nouvelle architecture (Databricks/Azure/Amplitude). Cette transition a pour but de centraliser et de traiter les donn√©es provenant de diverses sources (Salesforce, Drift, plan de tracking) afin d'am√©liorer le stockage et l'analyse des donn√©es.

### Objectifs Principaux
- **Migration compl√®te de l'infrastructure**
- **Centralisation des donn√©es dans Databricks**
- **Mise en place des automatisations**
- **Maintien de la continuit√© de service**
- **Optimisation des performances**

---

## üìÖ Historique du Projet

### Timeline des R√©unions et Progr√®s

#### Sprint 1 : Weekly - 12 Novembre
- **Travail r√©alis√©** : Pr√©paration des premiers scripts sur Databricks.
- **Probl√®mes rencontr√©s** :
  - Probl√®me de cr√©ation de destination Amplitude.
  - Probl√®me d'autorisation sur GitHub.
- **Solutions trouv√©es** : Aucune solution d√©finitive √† ce stade.
- **Temps de travail** : 3 jours.

#### Sprint 2 : Weekly - 18 Novembre
- **Travail r√©alis√©** : Mise en place du connecteur Amplitude vers Databricks et tests.
- **Probl√®mes rencontr√©s** :
  - Co√ªt pour environ 1000 donn√©es : 400 ‚Ç¨.
  - Probl√®me d'autorisation Salesforce pour la cr√©ation d'applications.
- **Solutions trouv√©es** : Aucune solution d√©finitive √† ce stade.
- **Temps de travail** : 3 jours.

#### Sprint 3 : Weekly - 26 Novembre
- **Travail r√©alis√©** : Script de migration Salesforce, cr√©ation et tests.
- **Probl√®mes rencontr√©s** :
  - Donn√©es ant√©rieures √† 1 mois ne s'importent pas dans Databricks.
  - Les donn√©es ne sont pas envoy√©es correctement.
- **Solutions trouv√©es** : Mise en place d'une double importation pour garantir que toutes les donn√©es n√©cessaires soient transf√©r√©es.
- **Co√ªt** : Environ 50 ‚Ç¨ pour 200 √©v√©nements envoy√©s.
- **Temps de travail** : 3 jours.

#### Sprint 4 et 5 : Weekly - 10 D√©cembre
- **Travail r√©alis√©** : Cr√©ation d'un environnement local, d√©ploiement sur Databricks ou Azure lorsque l'acc√®s aux logs sera disponible. Cr√©ation de compatibilit√© des scripts pour un double environnement.
- **Probl√®mes rencontr√©s** :
  - Architecture lourde due au triple environnement.
  - Rendre les scripts compatibles pour Azure/local et Databricks/local.
- **Solutions trouv√©es** : Cr√©ation d'un environnement local pour effectuer les tests.
- **Temps de travail** : 7 jours.

#### Sprint 6 : Weekly - 17 D√©cembre
- **Travail r√©alis√©** : Ajustements pour rendre compatibles les librairies Spark et Salesforce.
- **Probl√®mes rencontr√©s** :
  - Clusters Databricks instables, red√©marrages fr√©quents.
- **Solutions trouv√©es** : Recherche d'une solution pour un cluster stable.
- **Temps de travail** : 3 jours.

---

## üö® Probl√®mes Majeurs Identifi√©s

1. **Probl√®mes d'Autorisation** : Acc√®s limit√© aux ressources n√©cessaires sur Amplitude, Azure et Salesforce.
2. **Environnement de D√©veloppement** : Incompatibilit√©s entre les environnements locaux et Databricks, entra√Ænant des instabilit√©s.
3. **Gestion des Donn√©es** : Difficult√©s dans la validation et l'int√©gration des donn√©es provenant de diff√©rentes sources.
4. **Limitations des Workflows Databricks** : Les workflows de Databricks, principalement con√ßus pour l'analyse de donn√©es et de petites automatisations p√©riodiques, ne r√©pondent pas efficacement aux exigences de notre projet de grande envergure qui n√©cessite des automatisations complexes et continues.

---

## üí° Solutions Identifi√©es

Les solutions d'automatisation de Databricks qui m'ont √©t√© impos√©es sont beaucoup trop co√ªteuses et contraignantes. Databricks est principalement d√©di√© √† la cr√©ation de notebooks pour l'analyse de donn√©es ou de petites automatisations. La cr√©ation de connecteurs alourdit √©galement le projet.

### Solution Propos√©e

Amplitude vient de cr√©er une nouvelle destination de donn√©es Azure Blob Storage native. Voici comment nous pouvons proc√©der :

1. **Amplitude ‚Üí Azure Blob Storage** : 
   - Exportez les donn√©es depuis Amplitude (√©v√©nements, utilisateurs fusionn√©s) directement dans Azure Blob Storage gr√¢ce √† l'int√©gration native. Les fichiers sont g√©n√©ralement en format JSON, CSV ou Parquet.

2. **Azure Blob Storage ‚Üí Azure Synapse Analytics** : 
   - Chargez les donn√©es dans Synapse via :
     - **PolyBase** : Requ√™tes directes sur les fichiers Blob sans duplication.
     - **COPY INTO** : Importation des fichiers dans des tables internes pour des analyses plus rapides.
   - **Automatisation** : Utilisez Synapse Pipelines pour planifier et orchestrer les flux de donn√©es entre Blob Storage et Synapse.

### Choix de l'Automatisation

Pour l'automatisation, il faudra choisir entre deux options :

- **n8n** : Si vous optez pour n8n, cela permettra une int√©gration facile gr√¢ce √† des scripts d√©j√† r√©alis√©s. n8n est id√©al pour des workflows visuels et des automatisations simples.
  
- **Python h√©berg√© sur Azure Functions** : Cette option offre plus de flexibilit√© et de contr√¥le sur le traitement des donn√©es, mais n√©cessite une gestion plus technique. Cela peut √™tre plus adapt√© si des traitements complexes sont n√©cessaires.

### Estimation du Temps

| √âtape                                   | Dur√©e estim√©e |
|-----------------------------------------|---------------|
| Exportation Amplitude ‚Üí Blob Storage    | 3 heures      |
| Chargement Blob Storage ‚Üí Synapse       | 4 heures      |
| Automatisation avec Synapse Pipelines    | 5 heures      |
| V√©rifications et documentation          | 5 heures      |
| **Total estim√©**                       | **17 heures** |

### Avantages

- **Workflow sur n8n** install√© sur Azure : Adaptation facile gr√¢ce √† des scripts d√©j√† r√©alis√©s.
- **Python h√©berg√© sur Azure Functions** : Flexibilit√© pour des traitements plus complexes.
- **Point d'alerte** : Afin de faciliter cette int√©gration, j'aurais besoin que tous les acc√®s soient d√©bloqu√©s.

Cette solution peut √™tre rapidement mise en place, sera beaucoup plus facile √† maintenir et sera beaucoup moins co√ªteuse.

---

## ‚ö†Ô∏è Points de Vigilance

- **Suivi des Autorisations** : Continuer √† surveiller l'acc√®s aux ressources critiques pour √©viter des blocages futurs.
- **Stabilit√© des Environnements** : Assurer que les environnements de d√©veloppement et de production restent synchronis√©s et stables.
- **Documentation** : Maintenir une documentation √† jour pour faciliter la communication entre les √©quipes et garantir la continuit√© des op√©rations.

---

Ce rapport vise √† fournir une vue d'ensemble claire et concise de l'√©tat du projet Novade, en mettant l'accent sur les d√©fis et les solutions. Nous restons engag√©s √† travailler en √©troite collaboration avec toutes les parties prenantes pour assurer le succ√®s de cette migration.
