# Projet Novade - √âtat et Analyse des Probl√®mes
*Mise √† jour du 16 d√©cembre 2024*

## Introduction

Le projet Novade repr√©sente une migration complexe d'infrastructure technique, passant d'une solution √©prouv√©e (n8n/Segment/BigQuery) vers une nouvelle architecture (Databricks/Azure/Amplitude). Cette transition implique la centralisation et le traitement de donn√©es provenant de multiples sources (Salesforce, Drift, plan de tracking) avec un double objectif de stockage et d'analyse.

### Contexte Actuel
- **Progression** : 25% du projet r√©alis√©
- **√âtat** : Blocages techniques majeurs
- **Priorit√©** : R√©solution urgente des probl√®mes d'autorisation

### D√©fis Principaux
1. Probl√®mes d'autorisation multiples (Databricks, Azure, Salesforce)
2. Incompatibilit√©s environnement local/Databricks
3. Acc√®s limit√© aux logs et monitoring
4. Complexit√© de la migration multi-plateformes

### Impact Business
- Retard sur le planning initial
- Risque sur la qualit√© des donn√©es
- N√©cessit√© d'ajustements budg√©taires
- Complexit√© technique sous-estim√©e

<style>
.section {
    border: 1px solid #ddd;
    border-radius: 8px;
    padding: 15px;
    margin: 10px 0;
    background-color: #fff;
}

.section summary {
    font-weight: bold;
    cursor: pointer;
    padding: 8px;
    background-color: #f8f9fa;
    border-radius: 6px;
}

.section summary:hover {
    background-color: #e9ecef;
}

.status-critical {
    color: #dc3545;
    font-weight: bold;
}

.status-warning {
    color: #ffc107;
    font-weight: bold;
}

.status-success {
    color: #28a745;
    font-weight: bold;
}
</style>

<div class="section">
<details>
<summary>üìä Pr√©sentation du Projet</summary>

### Contexte
Projet de migration et centralisation des donn√©es pour Novade, impliquant une transition complexe d'architecture technique.

### Ancienne Architecture
- **Stack Technique** : n8n, Segment, BigQuery, Salesforce
- **Fonctionnement** : Solution fonctionnelle et stable
- **Gestion des Donn√©es** : Centralis√©e et automatis√©e

### Nouvelle Architecture
- **Workflow** : Databricks
- **Base de Donn√©es** : Databricks
- **Webhooks** : Microsoft Azure
- **Dashboard & Centralisation** : Amplitude
- **Int√©grations** : Multiples sources de donn√©es

### Sources de Donn√©es
- Plan de tracking
- Salesforce
- Drift
- Donn√©es historiques BigQuery

### Objectifs Principaux
1. Migration compl√®te de l'infrastructure
2. Centralisation des donn√©es dans Databricks
3. Mise en place des automatisations
4. Maintien de la continuit√© de service
5. Optimisation des performances

### D√©fis Techniques
- Migration complexe multi-plateformes
- Gestion des autorisations multiples
- Compatibilit√© environnement local/cloud
- Stabilit√© de l'infrastructure
- Synchronisation temps r√©el

### Contraintes Sp√©cifiques
- Ex√©cution depuis la racine du projet
- Fichiers Python dans `local_workspace`
- Configuration via fichiers √† la racine
- Logs en anglais, communication en fran√ßais
</details>
</div>

<div class="section">
<details>
<summary>üìä Liste des T√¢ches</summary>

### 1. Webhook Amplitude ‚Üí Databricks
- Cr√©ation d'un script Azure Function pour capturer les √©v√©nements Amplitude
- Configuration de l'appel API pour d√©clencher un script Python Notebook dans Databricks
- Impl√©mentation de la validation des donn√©es avant stockage
- Test du webhook pour v√©rifier la r√©ception des donn√©es Amplitude
- Gestion des erreurs via logs et alertes

### 2. Scripts P√©riodiques d'Organisation des Donn√©es
- √âcriture des scripts Python pour organiser les donn√©es brutes en tables finales
- Planification des jobs p√©riodiques dans Databricks
- Impl√©mentation des tests de v√©rification d'int√©grit√© des donn√©es
- Automatisation des alertes en cas de probl√®mes

### 3. Cr√©ation des Tables pour Amplitude
- Identification des types de donn√©es √† stocker dans les tables pour Amplitude
- Cr√©ation des tables temporaires pour stocker les donn√©es brutes Amplitude
- Cr√©ation des tables finales pour organiser les donn√©es
- D√©finition des sch√©mas pour chaque table
- Mise en place des index et optimisation des performances
- Test d'insertion et d'organisation des donn√©es

### 4. R√©cup√©ration des √âv√©nements Drift ‚Üí Amplitude
- √âcriture d'un script pour r√©cup√©rer les √©v√©nements Drift
- Planification du script sur Databricks pour ex√©cution p√©riodique
- Envoi des donn√©es Drift vers Amplitude
- Test de r√©ception des donn√©es dans Amplitude et Databricks

### 5. R√©cup√©ration des Donn√©es Salesforce ‚Üí Amplitude
- √âcriture d'un script pour r√©cup√©rer les √©v√©nements et utilisateurs de Salesforce
- Planification du script sur Databricks pour ex√©cution p√©riodique
- Envoi des donn√©es Salesforce vers Amplitude
- Test de r√©ception des donn√©es dans Amplitude et Databricks

### 6. Migration des Scripts n8n ‚Üí Databricks
- R√©√©criture de chaque script n8n en Python pour Databricks
- Test de chaque script Python sur Databricks
- Planification des scripts dans un scheduler
- Automatisation de la gestion des erreurs et alertes

### 7. Migration des Donn√©es BigQuery ‚Üí Amplitude
- Export des donn√©es existantes depuis BigQuery
- Cr√©ation d'un script pour envoyer les donn√©es vers Amplitude
- Configuration d'Amplitude pour rediriger les donn√©es vers Databricks
- Test de r√©ception des donn√©es dans Amplitude et Databricks

### 8. Tracking en Double sur Amplitude
- Analyse des scripts de tracking actuels sur novade.com
- Duplication du tracking existant en double via Amplitude
- Test et validation du tracking en parall√®le

### 9. Configuration et Test de l'Infrastructure
- Configuration des tests pour valider le bon fonctionnement des int√©grations
- Validation des performances et de l'int√©grit√© des donn√©es
- R√©alisation des tests de charge pour l'infrastructure
- Mise en place des tableaux de bord de monitoring

### 10. Cr√©ation de la Documentation
- R√©daction de la documentation technique compl√®te
- Formation des √©quipes techniques de Novade

### 11. Gestion de Projet
- Planification
- Suivi
- Communication
- Cl√¥ture du projet
</details>
</div>

<div class="section">
<details>
<summary>üìä √âtat Actuel du Projet</summary>

### Vue d'Ensemble
- **Phase en cours** : Migration n8n ‚Üí Databricks/Amplitude
- **Statut** : <span class="status-critical">Bloqu√© - Probl√®mes techniques critiques</span>
- **Priorit√©** : Haute
- **Progr√®s** : ~25%

### Contexte Initial
- Migration depuis stack n8n/Segment/BigQuery/Salesforce
- Nouvelle stack : Databricks/Azure/Amplitude
- Sources de donn√©es : Plan de tracking, Salesforce, Drift

### Blocages Majeurs
1. **Probl√®mes d'Autorisation** <span class="status-critical">(CRITIQUE)</span>
   - Acc√®s Databricks incomplet (cr√©ation cluster)
   - Logs Azure inaccessibles
   - Permissions Salesforce partielles
   - Configuration Amplitude incompl√®te

2. **Environnement de D√©veloppement** <span class="status-warning">(INSTABLE)</span>
   - Incompatibilit√©s local/Databricks
   - D√©pendances complexes (Spark, Java)
   - Clusters instables (red√©marrages fr√©quents)
   - Organisation du code non structur√©e

### √âtat des Composants
- **Webhook Amplitude** : 
  - Base fonctionnelle ‚úÖ
  - Gestion d'erreurs bloqu√©e ‚õî
  - Tests incomplets ‚ö†Ô∏è

- **Scripts P√©riodiques** :
  - En cours de revue üîÑ
  - Probl√®mes de permissions ‚õî
  - Tests √† impl√©menter ‚ö†Ô∏è

- **Tables Amplitude** :
  - Cr√©ation en cours üîÑ
  - Sch√©mas d√©finis ‚úÖ
  - Performance non optimis√©e ‚ö†Ô∏è

### M√©triques Actuelles
- **Volum√©trie** : ~37 000 contacts √† traiter
- **Performance** : Non mesurable (environnement instable)
- **Taux d'erreur** : Non mesurable (logs inaccessibles)
- **Couverture de tests** : 0%

### Solutions Temporaires en Place
1. **Environnement Local**
   - D√©veloppement en local avec GitHub
   - D√©ploiement vers Databricks
   - Tests locaux avant push

2. **Contournements**
   - Mode d√©veloppement local sans Spark
   - Tests manuels des composants
   - Documentation d√©taill√©e des probl√®mes

### Impact sur le Planning
- Retard significatif sur le planning initial
- Blocages techniques multiples
- D√©pendances sur les autorisations
- Complexit√© accrue de la maintenance
</details>
</div>

<div class="section">
<details>
<summary>üö® Probl√®mes Majeurs Identifi√©s</summary>

### 1. Probl√®mes d'Autorisation et d'Acc√®s
- **Databricks**
  - Permissions insuffisantes pour la cr√©ation de clusters
  - Acc√®s limit√© aux notebooks et √† une partie de la db
  - Probl√®mes de connexion avec l'environnement local

- **Azure**
  - Pas d'acc√®s aux logs des fonctions
  - Limitations sur la configuration des webhooks
  - Probl√®mes de monitoring des √©v√©nements
  - Restrictions sur la gestion des erreurs

- **Salesforce & Amplitude**
  - Autorisations partielles sur Salesforce
  - Configuration incompl√®te d'Amplitude
  - Probl√®mes de tokens et d'authentification
  - Limitations sur les API

### 2. Probl√®mes d'Architecture et d'Infrastructure
- **Environnement Local vs Databricks**
  - Incompatibilit√©s de versions Spark
  - Conflits de d√©pendances Java
  - Probl√®mes de configuration des clusters
  - Red√©marrages fr√©quents des clusters Databricks

- **Stack Technique**
  - Migration complexe depuis n8n/Segment/BigQuery
  - Double destination (Amplitude + Databricks)
  - Synchronisation multi-sources complexe
  - Gestion des formats de donn√©es h√©t√©rog√®nes

### 3. Probl√®mes de D√©veloppement
- **Organisation du Code**
  - Structure de projet d√©sorganis√©e
  - Tests dispers√©s et non standardis√©s
  - Documentation fragment√©e
  - Manque de coh√©rence dans les nomenclatures

- **Gestion des Donn√©es**
  - Validation des donn√©es incompl√®te
  - Probl√®mes de mapping des champs
  - Gestion des doublons complexe
  - Sch√©mas dynamiques difficiles √† maintenir

### 4. Probl√®mes de Performance et Monitoring
- **Performances**
  - Temps de traitement non optimis√©s
  - Latence webhook non mesur√©e
  - Probl√®mes de scalabilit√©
  - Gestion des lots inefficace

- **Monitoring**
  - Absence de m√©triques cl√©s
  - Pas de tableaux de bord de suivi
  - Alerting non configur√©
  - Logs incomplets ou inaccessibles

### 5. Probl√®mes de Gestion de Projet
- **Planning**
  - Retards significatifs sur le planning initial
  - D√©pendances bloquantes non identifi√©es
  - Estimation incorrecte des temps de d√©veloppement
  - Impact des probl√®mes d'autorisation sur les d√©lais

- **Communication**
  - Difficult√©s de coordination avec les √©quipes techniques
  - Probl√®mes d'escalade des incidents
  - Documentation insuffisante pour les √©quipes
  - Manque de visibilit√© sur l'avancement

### Impact sur le Projet
- **D√©lais**
  - Retard sur l'import initial des donn√©es
  - Blocage sur les d√©veloppements critiques
  - Report des phases de test
  - Ralentissement g√©n√©ral du projet

- **Qualit√©**
  - Risques sur l'int√©grit√© des donn√©es
  - Tests incomplets
  - Documentation partielle
  - Dette technique croissante
</details>
</div>

<div class="section">
<details>
<summary>üéØ Plan d'Action Imm√©diat</summary>

### Phase 1 : R√©solution des Blocages (48h)
1. **Gestion des Autorisations** (Urgent)
   - [ ] Inventaire des acc√®s manquants par plateforme
     - Databricks : cr√©ation clusters, acc√®s DB
     - Azure : acc√®s logs, configuration webhooks
     - Salesforce : permissions API
     - Amplitude : droits d'administration
   - [ ] Escalade aux √©quipes concern√©es
   - [ ] Suivi des demandes d'acc√®s
   - [ ] Documentation des acc√®s obtenus

2. **Stabilisation Environnement Local** (Prioritaire)
   - [ ] Standardisation de l'environnement
     - Python depuis la racine
     - Fichiers ex√©cutables dans `local_workspace`
     - Configuration √† la racine
   - [ ] Gestion des d√©pendances
     - Versions Spark compatibles
     - Configuration Java
     - Requirements.txt √† jour
   - [ ] Tests de compatibilit√©
     - Validation locale
     - Tests sur Databricks
     - V√©rification des connexions

3. **R√©organisation du Code** (Important)
   - [ ] Structure du projet
     - S√©paration claire webhook/salesforce
     - Organisation des tests
     - Centralisation des configurations
   - [ ] Documentation
     - README par composant
     - Guide de d√©ploiement
     - Proc√©dures de test

### Phase 2 : D√©veloppement S√©curis√© (72h)
1. **Mise en Place Tests**
   - [ ] Tests unitaires de base
     - Validation payload
     - Transformation donn√©es
     - Gestion erreurs
   - [ ] Tests d'int√©gration
     - Connexion Databricks
     - Envoi Amplitude
     - Webhooks Azure

2. **S√©curisation Donn√©es**
   - [ ] Validation donn√©es
     - Sch√©mas obligatoires
     - Formats attendus
     - Gestion doublons
   - [ ] Monitoring
     - Logs d√©taill√©s
     - M√©triques de base
     - Alertes critiques

3. **Optimisation Performance**
   - [ ] Traitement par lots
     - Taille optimale
     - Gestion m√©moire
     - Parall√©lisation
   - [ ] Gestion erreurs
     - Retry pattern
     - Circuit breaker
     - Logging avanc√©

### M√©triques de Suivi
- **Crit√®res de Succ√®s**
  - Environnement local stable et document√©
  - Tests de base fonctionnels
  - Acc√®s et permissions r√©solus
  - Premiers imports r√©ussis

- **Points de Contr√¥le**
  - Validation quotidienne des acc√®s
  - Tests automatis√©s
  - M√©triques de performance
  - Documentation √† jour

### Communication
- Daily avec √©quipe technique
- Points hebdomadaires stakeholders
- Documentation des blocages
- Suivi des escalades

### Livrables Attendus
1. **48h**
   - Inventaire complet des acc√®s
   - Environnement local stable
   - Structure projet claire

2. **72h**
   - Tests de base fonctionnels
   - Premier import test r√©ussi
   - Documentation technique initiale
</details>
</div>

<div class="section">
<details>
<summary>üìã T√¢ches en Cours</summary>

### 1. Webhook Amplitude ‚Üí Databricks (En Review)
- [x] Cr√©ation script Azure Function
  - Endpoint webhook fonctionnel
  - Structure de base en place
  - Tests initiaux valid√©s
- [x] Configuration API Databricks
  - Connexion √©tablie
  - Param√®tres de base configur√©s
- [x] Validation donn√©es
  - Format payload v√©rifi√©
  - Sch√©mas d√©finis
- [ ] Gestion des erreurs (Bloqu√©)
  - Acc√®s logs manquant
  - Monitoring √† configurer
  - Alertes √† mettre en place

### 2. Tables et Donn√©es (En Cours)
- [ ] Tables Amplitude
  - [x] Identification des types de donn√©es
  - [ ] Tables temporaires en cr√©ation
  - [ ] Tables finales en pr√©paration
  - [ ] Sch√©mas en cours de d√©finition
  - [ ] Tests d'insertion √† faire

- [ ] Organisation des Donn√©es
  - [x] Scripts de base ÔøΩÔøΩcrits
  - [ ] Jobs p√©riodiques en attente
  - [ ] Tests d'int√©grit√© √† impl√©menter
  - [ ] Alertes √† configurer

### 3. Int√©grations Sources (Mixte)
#### Salesforce (En R√©vision)
- [x] Script de r√©cup√©ration
  - [x] Contacts
  - [x] Leads
  - [x] Opportunit√©s
- [x] Planification (5min)
- [ ] Double destination
  - [ ] Envoi Amplitude (Probl√®mes)
  - [ ] Stockage Databricks (√Ä valider)

#### Probl√®mes Identifi√©s
- Format des √©v√©nements non conforme aux sp√©cifications Amplitude
- Probl√®mes de performance sur les requ√™tes Salesforce
- Gestion des erreurs insuffisante
- Monitoring incomplet des envois

#### Actions Correctives
- [ ] R√©vision du format des √©v√©nements
  - [ ] Structure contact
  - [ ] Structure identify
  - [ ] Validation JSON
- [ ] Optimisation des requ√™tes
  - [ ] Limitation des champs
  - [ ] Gestion du rate limiting
  - [ ] Batch processing
- [ ] Am√©lioration monitoring
  - [ ] Logs d√©taill√©s
  - [ ] M√©triques de performance
  - [ ] Alertes en cas d'√©chec

#### Prochaines √âtapes
1. Correction du format des √©v√©nements
2. Tests avec petit volume (100 contacts)
3. Validation compl√®te des donn√©es
4. D√©ploiement progressif

#### Drift (En Cours)
- [ ] R√©cup√©ration √©v√©nements
  - [ ] Analyse des types d'√©v√©nements
  - [ ] Format de donn√©es d√©fini
  - [ ] Script de r√©cup√©ration en cours
  - [ ] Tests unitaires √† faire

#### Synchronisation
- [ ] Configuration Amplitude
- [ ] Tests connexion

### 4. Migration n8n (En Cours)
- [ ] Analyse des workflows
  - [x] Identification des scripts
  - [ ] Documentation des flux
  - [ ] Points d'int√©gration
- [ ] Conversion
  - [ ] Scripts Python
  - [ ] Tests unitaires
  - [ ] Validation fonctionnelle

### 5. Infrastructure (En Cours)
- [ ] Tests et Validation
  - [ ] Tests int√©gration
  - [ ] Tests performance
  - [ ] Tests charge
- [ ] Monitoring
  - [ ] Dashboards
  - [ ] Alertes
  - [ ] Logs

### Points de Blocage Actuels
1. **Autorisations** (Critique)
   - Cr√©ation clusters Databricks
   - Acc√®s logs Azure
   - Configuration compl√®te Amplitude

2. **Environnement** (Important)
   - Incompatibilit√©s versions
   - Configuration Spark
   - Stabilit√© clusters

3. **Tests** (√Ä D√©marrer)
   - Framework √† mettre en place
   - Environnement de test √† configurer
   - Donn√©es de test √† pr√©parer

### Prochaines Actions (24-48h)
1. **Priorit√© 1**
   - R√©solution acc√®s Databricks
   - Stabilisation environnement local
   - Tests basiques webhook

2. **Priorit√© 2**
   - Finalisation tables Amplitude
   - Tests int√©gration Drift
   - Documentation technique

### M√©triques Actuelles
- **Webhook** : 80% compl√©t√©
- **Tables** : 40% compl√©t√©
- **Int√©grations** : 60% compl√©t√©
- **Tests** : 20% compl√©t√©
</details>
</div>

<div class="section">
<details>
<summary>üîÑ Int√©grations en Attente</summary>

### 1. Drift ‚Üí Amplitude (En Cours)
#### √âtat Actuel
- [ ] R√©cup√©ration √©v√©nements
  - [ ] Analyse des types d'√©v√©nements
  - [ ] Format de donn√©es d√©fini
  - [ ] Script de r√©cup√©ration en cours
  - [ ] Tests unitaires √† faire

#### Blocages
- Acc√®s API Drift incomplet
- Format des donn√©es √† valider
- Tests environnement √† configurer

#### Prochaines √âtapes
- Finalisation script r√©cup√©ration
- Tests avec donn√©es r√©elles
- Documentation technique

### 2. Salesforce ‚Üí Amplitude (En R√©vision)
#### √âtat Actuel
- [x] Script de r√©cup√©ration
  - [x] Contacts
  - [x] Leads
  - [x] Opportunit√©s
- [x] Planification (5min)
- [ ] Double destination
  - [ ] Envoi Amplitude (Probl√®mes)
  - [ ] Stockage Databricks (√Ä valider)

#### Probl√®mes Identifi√©s
- Format des √©v√©nements non conforme aux sp√©cifications Amplitude
- Probl√®mes de performance sur les requ√™tes Salesforce
- Gestion des erreurs insuffisante
- Monitoring incomplet des envois

#### Actions Correctives
- [ ] R√©vision du format des √©v√©nements
  - [ ] Structure contact
  - [ ] Structure identify
  - [ ] Validation JSON
- [ ] Optimisation des requ√™tes
  - [ ] Limitation des champs
  - [ ] Gestion du rate limiting
  - [ ] Batch processing
- [ ] Am√©lioration monitoring
  - [ ] Logs d√©taill√©s
  - [ ] M√©triques de performance
  - [ ] Alertes en cas d'√©chec

#### Prochaines √âtapes
1. Correction du format des √©v√©nements
2. Tests avec petit volume (100 contacts)
3. Validation compl√®te des donn√©es
4. D√©ploiement progressif

### 3. BigQuery ‚Üí Amplitude/Databricks (En Attente)
#### √Ä Faire
- [ ] Export donn√©es historiques
  - [ ] Analyse volum√©trie
  - [ ] Script d'export
  - [ ] Validation donn√©es
- [ ] Migration
  - [ ] Transformation donn√©es
  - [ ] Import Amplitude
  - [ ] V√©rification int√©grit√©

#### Pr√©requis
- Acc√®s BigQuery √† configurer
- Format de mapping √† d√©finir
- Environnement de test √† pr√©parer

### 4. Plan de Tracking ‚Üí Amplitude (Bloqu√©)
#### √âtat Actuel
- [ ] Analyse existant
  - [ ] Scripts actuels
  - [ ] Points de tracking
  - [ ] Format donn√©es
- [ ] Migration
  - [ ] Nouveau format
  - [ ] Tests parall√®les
  - [ ] Validation donn√©es

#### Blocages
- Documentation incompl√®te
- Acc√®s configurations actuelles
- Environnement de test

### 5. Migration n8n ‚Üí Databricks (En Cours)
#### En Cours
- [ ] Analyse des workflows
  - [x] Identification des scripts
  - [ ] Documentation des flux
  - [ ] Points d'int√©gration
- [ ] Conversion
  - [ ] Scripts Python
  - [ ] Tests unitaires
  - [ ] Validation fonctionnelle

#### Risques Identifi√©s
- Complexit√© des workflows
- D√©pendances multiples
- Tests incomplets

### Points de Vigilance G√©n√©raux
1. **Donn√©es**
   - Validation des formats
   - Gestion des doublons
   - Int√©grit√© des donn√©es

2. **Performance**
   - Temps de traitement
   - Utilisation ressources
   - Gestion des erreurs

3. **Monitoring**
   - Alertes en place
   - Logs accessibles
   - Tableaux de bord

### Prochaines Actions Prioritaires
1. **Imm√©diat (24h)**
   - Finalisation Drift
   - Tests BigQuery
   - Documentation workflows

2. **Court Terme (72h)**
   - Migration plan de tracking
   - Validation compl√®te Salesforce
   - Tests d'int√©gration
</details>
</div>

<div class="section">
<details>
<summary>‚ö†Ô∏è Points de Vigilance Critiques</summary>

### 1. Probl√®mes d'Autorisation (URGENT)
- **Databricks**
  - [ ] Cr√©ation de clusters bloqu√©e
  - [ ] Acc√®s limit√© aux notebooks
  - [ ] Permissions DB incompl√®tes
  - [ ] Configuration des jobs restreinte

- **Azure**
  - [ ] Logs inaccessibles
  - [ ] Configuration webhook limit√©e
  - [ ] Monitoring incomplet
  - [ ] Gestion des erreurs impossible

- **Amplitude & Salesforce**
  - [ ] Tokens d'authentification √† s√©curiser
  - [ ] Permissions API √† compl√©ter
  - [ ] Webhooks √† configurer
  - [ ] Rate limiting √† g√©rer

### 2. Environnement de D√©veloppement (CRITIQUE)
- **Incompatibilit√©s**
  - [ ] Versions Spark local/Databricks
  - [ ] D√©pendances Java
  - [ ] Configurations Python
  - [ ] Packages syst√®me

- **Stabilit√©**
  - [ ] Red√©marrages fr√©quents des clusters
  - [ ] Connexions instables
  - [ ] Pertes de session
  - [ ] Timeouts fr√©quents

### 3. Organisation du Code (IMPORTANT)
- **Structure**
  - [ ] R√©organiser les fichiers Python
  - [ ] Centraliser les configurations
  - [ ] Standardiser les logs
  - [ ] Nettoyer les tests

- **Documentation**
  - [ ] Mise √† jour des README
  - [ ] Documentation des API
  - [ ] Guides de d√©ploiement
  - [ ] Proc√©dures de test

### 4. Performance et Donn√©es (CRITIQUE)
- **Validation**
  - [ ] Format des √©v√©nements
  - [ ] Champs obligatoires
  - [ ] Gestion des doublons
  - [ ] Int√©grit√© des donn√©es

- **Monitoring**
  - [ ] Temps de traitement
  - [ ] Taux d'erreur
  - [ ] Utilisation ressources
  - [ ] Alertes

### Actions Prioritaires (24-48h)
1. **Autorisations (URGENT)**
   - Escalade probl√®mes d'acc√®s
   - Documentation des besoins
   - Tests de validation
   - Mise en place workarounds

2. **Environnement (CRITIQUE)**
   - Standardisation configuration
   - Tests de compatibilit√©
   - Documentation d√©ploiement
   - Proc√©dures de recovery

3. **Code (IMPORTANT)**
   - Restructuration projet
   - Nettoyage d√©pendances
   - Mise √† jour documentation
   - Organisation tests

### M√©triques √† Surveiller
- **Performance**
  - Temps traitement < 2min/1000 records
  - Latence webhook < 1s
  - CPU cluster < 80%
  - M√©moire < 70%

- **Qualit√©**
  - Taux erreur < 0.1%
  - Couverture tests > 80%
  - Doublons = 0%
  - Data loss = 0%

### Rappels Critiques
- Ex√©cuter depuis la racine du projet
- V√©rifier les configurations avant d√©ploiement
- Tester sur petit volume avant production
- Documenter tous les changements
- Maintenir les logs √† jour
- Sauvegarder les donn√©es critiques

</details>
</div>

<div class="section">
<details>
<summary>üìù Recommandations</summary>

### 1. Actions Imm√©diates (24-48h)
#### 1.1 Stabilisation Environnement
- **Local**
  - [ ] Standardiser l'environnement Python
  - [ ] Nettoyer les d√©pendances conflictuelles
  - [ ] Centraliser les fichiers de configuration
  - [ ] Organiser les scripts dans `local_workspace`

- **Databricks**
  - [ ] Documenter les erreurs de connexion
  - [ ] Cr√©er un cluster de d√©veloppement stable
  - [ ] Tester les connexions de base
  - [ ] Valider les permissions minimales

#### 1.2 Gestion des Acc√®s
- **Escalade Prioritaire**
  - [ ] Liste exhaustive des acc√®s manquants
  - [ ] Demande formelle par plateforme
  - [ ] Suivi quotidien des tickets
  - [ ] Tests de validation post-acc√®s

- **Solutions Temporaires**
  - [ ] D√©veloppement en mode d√©grad√©
  - [ ] Tests locaux simul√©s
  - [ ] Documentation des workarounds
  - [ ] Plan de migration vers solution finale

### 2. Actions √† Court Terme (1-2 semaines)
#### 2.1 Organisation du Code
- **Structure**
  - [ ] S√©paration claire des composants
  - [ ] Standardisation des logs
  - [ ] Gestion centralis√©e des configurations
  - [ ] Tests unitaires de base

- **Documentation**
  - [ ] Guide d'installation
  - [ ] Proc√©dures de d√©ploiement
  - [ ] Points de contr√¥le critiques
  - [ ] Troubleshooting guide

#### 2.2 Monitoring et Tests
- **Base Monitoring**
  - [ ] Logs essentiels
  - [ ] M√©triques de performance
  - [ ] Alertes critiques
  - [ ] Dashboard basique

- **Tests Fondamentaux**
  - [ ] Validation des donn√©es
  - [ ] Tests de connexion
  - [ ] V√©rification des formats
  - [ ] Tests d'int√©gration simples

### 3. Actions √† Moyen Terme (2-4 semaines)
#### 3.1 Optimisation
- **Performance**
  - [ ] Optimisation des requ√™tes
  - [ ] Gestion du batch processing
  - [ ] Configuration des clusters
  - [ ] Monitoring avanc√©

- **S√©curit√©**
  - [ ] Migration vers Key Vault
  - [ ] Gestion des secrets
  - [ ] Validation des acc√®s
  - [ ] Audit des logs

#### 3.2 Automatisation
- **D√©ploiement**
  - [ ] Pipeline CI/CD
  - [ ] Tests automatis√©s
  - [ ] D√©ploiement continu
  - [ ] Rollback automatique

- **Maintenance**
  - [ ] Scripts de maintenance
  - [ ] Backup automatique
  - [ ] Nettoyage donn√©es
  - [ ] Rotation des logs

### 4. Actions √† Long Terme (1-2 mois)
#### 4.1 Industrialisation
- **Infrastructure**
  - [ ] Architecture haute disponibilit√©
  - [ ] Scaling automatique
  - [ ] Disaster recovery
  - [ ] Monitoring complet

- **Documentation**
  - [ ] Documentation technique compl√®te
  - [ ] Guides utilisateurs
  - [ ] Proc√©dures d'exploitation
  - [ ] Plans de maintenance

### Points de Vigilance
1. **Priorit√©s**
   - Stabilit√© avant fonctionnalit√©s
   - Tests avant d√©ploiement
   - Documentation continue
   - Communication r√©guli√®re

2. **Risques**
   - D√©pendances externes
   - Compatibilit√© versions
   - Performance donn√©es
   - S√©curit√© acc√®s

3. **Contr√¥le**
   - Validation √©tape par √©tape
   - Tests r√©guliers
   - M√©triques claires
   - Feedback utilisateurs

### M√©triques de Succ√®s
- **Technique**
  - Uptime > 99.9%
  - Latence < 1s
  - Erreurs < 0.1%
  - Tests > 80%

- **Projet**
  - D√©lais respect√©s
  - Budget maintenu
  - Satisfaction utilisateurs
  - Documentation compl√®te

</details>
</div>

<div class="section">
<details>
<summary>üîç Configuration Requise</summary>

### 1. Structure du Projet
```plaintext
project_root/
‚îú‚îÄ‚îÄ .env                    # Variables d'environnement (ne pas commiter)
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ databricks.yaml     # Configuration Databricks (ne pas commiter)
‚îÇ   ‚îú‚îÄ‚îÄ amplitude.yaml      # Configuration Amplitude (ne pas commiter)
‚îÇ   ‚îî‚îÄ‚îÄ azure.yaml         # Configuration Azure (ne pas commiter)
‚îú‚îÄ‚îÄ local_workspace/
‚îÇ   ‚îú‚îÄ‚îÄ webhook/
‚îÇ   ‚îú‚îÄ‚îÄ salesforce_sync/
‚îÇ   ‚îî‚îÄ‚îÄ drift_sync/
‚îî‚îÄ‚îÄ tests/
```

### 2. Pr√©requis Syst√®me
- Python 3.8+
- Java 8+ (pour Spark local)
- Git
- Acc√®s Internet stable
- RAM minimale : 8GB
- Espace disque : 20GB

### 3. Fichiers de Configuration
#### 3.1 Structure .env
```plaintext
# Databricks
DATABRICKS_HOST=xxx
DATABRICKS_TOKEN=xxx
DATABRICKS_CLUSTER_ID=xxx

# Amplitude
AMPLITUDE_API_KEY=xxx

# Azure
AZURE_FUNCTION_URL=xxx

# Salesforce
SF_USERNAME=xxx
SF_PASSWORD=xxx
SF_TOKEN=xxx
```

### 4. D√©pendances Python
```plaintext
# requirements.txt
databricks-connect>=13.0
requests>=2.28.0
python-dotenv>=0.19.0
simple-salesforce>=1.12.0
amplitude-analytics>=1.1.0
azure-functions>=1.12.0
```

### 5. Points de Configuration Importants
- **Ex√©cution** : Toujours depuis la racine du projet
- **Fichiers Python** : Dans `local_workspace`
- **Logs** : En anglais, niveau INFO minimum
- **Tests** : Dans le dossier `tests`
- **Configuration** : Fichiers √† la racine

### 6. Acc√®s Requis
- **Databricks**
  - Acc√®s Workspace
  - Permissions Cluster
  - Acc√®s Tables

- **Azure**
  - Acc√®s Function App
  - Permissions Logs
  - Configuration Webhook

- **Amplitude**
  - Cl√© API
  - Acc√®s Dashboard
  - Permissions Projet

### 7. S√©curit√©
- Ne jamais commiter les fichiers `.env`
- Ne pas partager les tokens
- Utiliser des secrets s√©curis√©s
- Restreindre les acc√®s IP si possible
- Rotation r√©guli√®re des cl√©s

### 8. Rappels Critiques
- V√©rifier les configurations avant d√©ploiement
- Tester en local avant push
- Sauvegarder les configurations sensibles
- Documenter les changements
- Maintenir les acc√®s √† jour

</details>
</div>

<div class="section">
<details>
<summary>üìÖ Planning Propos√©</summary>

### Planning d'Ex√©cution sur 6 Semaines

### Semaine 1 : Setup & Configuration
#### Jour 1-2 : Environnement
- [ ] Clone du repository
- [ ] Installation environnement local
  ```bash
  # Dans project_root/
  python -m venv venv
  source venv/bin/activate  # ou venv\Scripts\activate sous Windows
  pip install -r requirements.txt
  ```
- [ ] V√©rification des acc√®s
  - Databricks
  - Azure
  - Amplitude
  - Salesforce

#### Jour 3-4 : Architecture
- [ ] Analyse du code existant
  - `webhook.py`
  - `historical_import.py`
  - Scripts de synchronisation
- [ ] Tests des composants existants
- [ ] Documentation des probl√®mes rencontr√©s

#### Jour 5 : Tests Initiaux
- [ ] Test connexions
- [ ] Validation formats donn√©es
- [ ] V√©rification logs

### Semaine 2 : Infrastructure
#### Jour 1-2 : Databricks
- [ ] Configuration cluster dev
  ```python
  # Example cluster config
  {
    "spark_version": "13.3.x-scala2.12",
    "node_type_id": "Standard_DS3_v2",
    "num_workers": 1
  }
  ```
- [ ] Tests connexion locale
- [ ] Validation tables

#### Jour 3-4 : Webhooks & Azure
- [ ] Setup Azure Functions
- [ ] Tests webhooks
- [ ] Validation payload

#### Jour 5 : Monitoring
- [ ] Setup logs
- [ ] Configuration alertes
- [ ] Tests monitoring

### Semaine 3 : D√©veloppement Core
#### Jour 1-2 : Import Donn√©es
```python
# Structure import attendue
def import_data(source, destination):
    """
    source: 'salesforce', 'drift', 'bigquery'
    destination: 'amplitude', 'databricks'
    """
    pass
```
- [ ] Import test Salesforce
- [ ] Import test Drift
- [ ] Validation donn√©es

#### Jour 3-4 : Synchronisation
- [ ] Setup jobs p√©riodiques
- [ ] Tests synchronisation
- [ ] Gestion erreurs

#### Jour 5 : Tests & Documentation
- [ ] Tests unitaires
- [ ] Tests int√©gration
- [ ] Documentation technique

### Semaine 4 : Int√©grations
#### Priorit√©s par Source
1. **Salesforce** (2 jours)
   - Format √©v√©nements
   - Synchronisation 5min
   - Validation donn√©es

2. **Drift** (2 jours)
   - Structure donn√©es
   - Tests connexion
   - Import initial

3. **BigQuery** (1 jour)
   - Export donn√©es
   - Import Amplitude
   - Validation

### Semaine 5 : Optimisation & Tests
#### Performance (3 jours)
- [ ] Optimisation requ√™tes
- [ ] Gestion batch
- [ ] Tests charge
```python
# Exemple batch processing
def process_batch(records, batch_size=1000):
    for i in range(0, len(records), batch_size):
        batch = records[i:i + batch_size]
        try:
            process_records(batch)
        except Exception as e:
            log_error(e, batch)
```

#### Tests (2 jours)
- [ ] Tests bout en bout
- [ ] Tests charge
- [ ] Documentation tests

### Semaine 6 : Finalisation
#### Documentation (3 jours)
- [ ] Guide technique
- [ ] Proc√©dures maintenance
- [ ] Troubleshooting

#### D√©ploiement (2 jours)
- [ ] Validation finale
- [ ] Mise en production
- [ ] Monitoring post-d√©ploiement

### Points de Contr√¥le Quotidiens
- Validation connexions
- V√©rification logs
- Tests basiques
- Push code comment√©

### M√©triques de Progression
- **Setup** : Environnement fonctionnel
- **Dev** : Tests passent
- **Prod** : Donn√©es synchronis√©es
- **Docs** : Documentation √† jour

### Contacts Cl√©s
- **Support Databricks** : √Ä d√©finir
- **Support Azure** : √Ä d√©finir
- **Support Amplitude** : √Ä d√©finir
- **√âquipe Novade** : √Ä d√©finir

### Rappels Importants
- Ex√©cuter depuis la racine
- V√©rifier `.env` avant tests
- Documenter les erreurs
- Commits clairs et document√©s
- Tests avant push

</details>
</div>

<div class="section">
<details>
<summary>üí∞ Budget et Facturation</summary>

### Vue d'Ensemble Financi√®re
- **Budget Initial** : 21 375,00 ‚Ç¨ HT
- **Acompte Novade (50%)** : 10 687,50 ‚Ç¨ HT
- **Montant Re√ßu par Thomas** : 6 000,00 ‚Ç¨ HT
- **Reste √† Facturer** : 10 687,50 ‚Ç¨ HT
- **Marge Tyrscale** : 7 125,00 ‚Ç¨ HT

### R√©partition Initiale
- **Jours Pr√©vus** : 24 jours
- **Gestion de Projet** : 4,5 jours (non consomm√©s)
- **D√©veloppement** : 19,5 jours

### √âtat Actuel
- **Complexit√© Additionnelle**
  - Probl√®mes d'autorisations multiples
  - Architecture technique plus complexe que pr√©vue
  - Int√©grations suppl√©mentaires n√©cessaires
  - Environnement de d√©veloppement complexe

### Proposition d'Ajustement
- **Enveloppe Suppl√©mentaire** : 5 000,00 ‚Ç¨ HT
  - Livrable √† la finalisation compl√®te du projet
  - Justifi√© par la complexit√© technique impr√©vue
  - Couvre les d√©veloppements additionnels n√©cessaires

### Justification
1. **Complexit√© Technique**
   - Migration multi-plateformes complexe
   - Probl√®mes d'autorisations non anticip√©s
   - Architecture technique plus sophistiqu√©e

2. **Travail Suppl√©mentaire**
   - D√©veloppement d'environnement local
   - Gestion des incompatibilit√©s
   - Tests et validations additionnels
   - Documentation extensive

3. **Reconnaissance Client**
   - Novade conscient des probl√®mes d'autorisation
   - Impact sur le planning initial
   - Complexit√© technique reconnue

### Options de Financement
1. **Solution Propos√©e**
   - Enveloppe suppl√©mentaire : 5 000,00 ‚Ç¨ HT
   - Paiement √† la livraison finale
   - Garantie de finalisation compl√®te

2. **Alternative**
   - Utilisation partielle de la marge Tyrscale
   - Maintien du budget initial
   - Ajustement du p√©rim√®tre

### √âtat des Paiements
1. **D√©j√† Re√ßu**
   - Acompte Novade : 10 687,50 ‚Ç¨ HT
   - Versement Thomas : 6 000,00 ‚Ç¨ HT

2. **√Ä Venir**
   - Solde Novade : 10 687,50 ‚Ç¨ HT
   - Bonus finalisation (si accept√©) : 5 000,00 ‚Ç¨ HT

### Points de Discussion
- Reconnaissance de la complexit√© technique
- Validation de l'enveloppe suppl√©mentaire
- Planning de facturation ajust√©
- Garanties de livraison

</details>
</div>
