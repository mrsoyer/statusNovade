# Projet Novade - √âtat et Analyse des Probl√®mes
*Mise √† jour du 16 d√©cembre 2024*

## Introduction

Le projet Novade repr√©sente une migration complexe d'infrastructure technique, passant d'une solution √©prouv√©e (n8n/Segment/BigQuery) vers une nouvelle architecture (Databricks/Azure/Amplitude). Cette transition implique la centralisation et le traitement de donn√©es provenant de multiples sources (Salesforce, Drift, plan de tracking) avec un double objectif de stockage et d'analyse.

![Plan Novade](https://i.ibb.co/TYYdjMp/Capture-d-e-cran-2024-12-16-a-13-21-23.png)

### Contexte Actuel
- **Progression** : 25% du projet r√©alis√©
- **√âtat** : Blocages techniques majeurs
- **Priorit√©** : R√©solution urgente des probl√®mes d'autorisation

### D√©fis Principaux
1. Probl√®mes d'autorisation multiples (Databricks, Azure, Salesforce)
2. Incompatibilit√©s environnement local/Databricks
3. Acc√®s limit√© aux logs et monitoring
4. Complexit√© de la migration multi-plateformes

### Impact Business
- Retard sur le planning initial
- Risque sur la qualit√© des donn√©es
- N√©cessit√© d'ajustements budg√©taires
- Complexit√© technique sous-estim√©e

<details>
<summary> üíª Pr√©sentation du Projet</summary>

### Contexte
Projet de migration et centralisation des donn√©es pour Novade, impliquant une transition complexe d'architecture technique.

### Ancienne Architecture
- **Stack Technique** : n8n, Segment, BigQuery, Salesforce
- **Fonctionnement** : Solution fonctionnelle et stable
- **Gestion des Donn√©es** : Centralis√©e et automatis√©e

### Nouvelle Architecture
- **Workflow** : Databricks
- **Base de Donn√©es** : Databricks
- **Webhooks** : Microsoft Azure
- **Dashboard & Centralisation** : Amplitude
- **Int√©grations** : Multiples sources de donn√©es

### Sources de Donn√©es
- Plan de tracking
- Salesforce
- Drift
- Donn√©es historiques BigQuery

### Objectifs Principaux
1. Migration compl√®te de l'infrastructure
2. Centralisation des donn√©es dans Databricks
3. Mise en place des automatisations
4. Maintien de la continuit√© de service
5. Optimisation des performances

### D√©fis Techniques
- Migration complexe multi-plateformes
- Gestion des autorisations multiples
- Compatibilit√© environnement local/cloud
- Stabilit√© de l'infrastructure
- Synchronisation temps r√©el

</details>

<details>
<summary> ‚úÖ Liste des T√¢ches</summary>

### 1. Webhook Amplitude ‚Üí Databricks
- Cr√©ation d'un script Azure Function pour capturer les √©v√©nements Amplitude
- Configuration de l'appel API pour d√©clencher un script Python Notebook dans Databricks
- Impl√©mentation de la validation des donn√©es avant stockage
- Test du webhook pour v√©rifier la r√©ception des donn√©es Amplitude
- Gestion des erreurs via logs et alertes

### 2. Scripts P√©riodiques d'Organisation des Donn√©es
- √âcriture des scripts Python pour organiser les donn√©es brutes en tables finales
- Planification des jobs p√©riodiques dans Databricks
- Impl√©mentation des tests de v√©rification d'int√©grit√© des donn√©es
- Automatisation des alertes en cas de probl√®mes

### 3. Cr√©ation des Tables pour Amplitude
- Identification des types de donn√©es √† stocker dans les tables pour Amplitude
- Cr√©ation des tables temporaires pour stocker les donn√©es brutes Amplitude
- Cr√©ation des tables finales pour organiser les donn√©es
- D√©finition des sch√©mas pour chaque table
- Mise en place des index et optimisation des performances
- Test d'insertion et d'organisation des donn√©es

### 4. R√©cup√©ration des √âv√©nements Drift ‚Üí Amplitude
- √âcriture d'un script pour r√©cup√©rer les ÔøΩÔøΩv√©nements Drift
- Planification du script sur Databricks pour ex√©cution p√©riodique
- Envoi des donn√©es Drift vers Amplitude
- Test de r√©ception des donn√©es dans Amplitude et Databricks

### 5. R√©cup√©ration des Donn√©es Salesforce ‚Üí Amplitude
- √âcriture d'un script pour r√©cup√©rer les √©v√©nements et utilisateurs de Salesforce
- Planification du script sur Databricks pour ex√©cution p√©riodique
- Envoi des donn√©es Salesforce vers Amplitude
- Test de r√©ception des donn√©es dans Amplitude et Databricks

### 6. Migration des Scripts n8n ‚Üí Databricks
- R√©√©criture de chaque script n8n en Python pour Databricks
- Test de chaque script Python sur Databricks
- Planification des scripts dans un scheduler
- Automatisation de la gestion des erreurs et alertes

### 7. Migration des Donn√©es BigQuery ‚Üí Amplitude
- Export des donn√©es existantes depuis BigQuery
- Cr√©ation d'un script pour envoyer les donn√©es vers Amplitude
- Configuration d'Amplitude pour rediriger les donn√©es vers Databricks
- Test de r√©ception des donn√©es dans Amplitude et Databricks

### 8. Tracking en Double sur Amplitude
- Analyse des scripts de tracking actuels sur novade.com
- Duplication du tracking existant en double via Amplitude
- Test et validation du tracking en parall√®le

### 9. Configuration et Test de l'Infrastructure
- Configuration des tests pour valider le bon fonctionnement des int√©grations
- Validation des performances et de l'int√©grit√© des donn√©es
- R√©alisation des tests de charge pour l'infrastructure
- Mise en place des tableaux de bord de monitoring

### 10. Cr√©ation de la Documentation
- R√©daction de la documentation technique compl√®te
- Formation des √©quipes techniques de Novade

### 11. Gestion de Projet
- Planification
- Suivi
- Communication
- Cl√¥ture du projet
</details>

<details>
<summary> üìä √âtat Actuel du Projet</summary>

### Vue d'Ensemble
- **Phase en cours** : Migration n8n ‚Üí Databricks/Amplitude
- **Statut** : ‚ö†Ô∏è Bloqu√© - Probl√®mes techniques critiques
- **Priorit√©** : Haute
- **Progr√®s** : ~25%

### Contexte Initial
- Migration depuis stack n8n/Segment/BigQuery/Salesforce
- Nouvelle stack : Databricks/Azure/Amplitude
- Sources de donn√©es : Plan de tracking, Salesforce, Drift

### Blocages Majeurs
1. **Probl√®mes d'Autorisation** ‚ö†Ô∏è (CRITIQUE)
   - Acc√®s Databricks incomplet (cr√©ation cluster)
   - Logs Azure inaccessibles
   - Permissions Salesforce partielles
   - Configuration Amplitude incompl√®te

2. **Environnement de D√©veloppement** ‚ö†Ô∏è (INSTABLE)
   - Incompatibilit√©s local/Databricks
   - D√©pendances complexes (Spark, Java)
   - Clusters instables (red√©marrages fr√©quents)
   - Organisation du code non structur√©e

### √âtat des Composants
- **Webhook Amplitude** : 
  - Base fonctionnelle ‚úÖ
  - Gestion d'erreurs bloqu√©e ‚õî
  - Tests incomplets ‚ö†Ô∏è

- **Scripts P√©riodiques** :
  - En cours de revue üîÑ
  - Probl√®mes de permissions ‚õî
  - Tests √† impl√©menter ‚ö†Ô∏è

- **Tables Amplitude** :
  - Cr√©ation en cours üîÑ
  - Sch√©mas d√©finis ‚úÖ
  - Performance non optimis√©e ‚ö†Ô∏è

### M√©triques Actuelles
- **Volum√©trie** : ~37 000 contacts √† traiter
- **Performance** : Non mesurable (environnement instable)
- **Taux d'erreur** : Non mesurable (logs inaccessibles)
- **Couverture de tests** : 0%

### Solutions Temporaires en Place
1. **Environnement Local**
   - D√©veloppement en local avec GitHub
   - D√©ploiement vers Databricks
   - Tests locaux avant push

2. **Contournements**
   - Mode d√©veloppement local sans Spark
   - Tests manuels des composants
   - Documentation d√©taill√©e des probl√®mes

### Impact sur le Planning
- Retard significatif sur le planning initial
- Blocages techniques multiples
- D√©pendances sur les autorisations
- Complexit√© accrue de la maintenance
</details>

<details>
<summary> üö® Probl√®mes Majeurs Identifi√©s</summary>

### 1. Probl√®mes d'Autorisation et d'Acc√®s
- **Databricks**
  - Permissions insuffisantes pour la cr√©ation de clusters
  - Acc√®s limit√© aux notebooks et √† une partie de la db
  - Probl√®mes de connexion avec l'environnement local

- **Azure**
  - Pas d'acc√®s aux logs des fonctions
  - Limitations sur la configuration des webhooks
  - Probl√®mes de monitoring des √©v√©nements
  - Restrictions sur la gestion des erreurs

- **Salesforce & Amplitude**
  - Autorisations partielles sur Salesforce
  - Configuration incompl√®te d'Amplitude
  - Probl√®mes de tokens et d'authentification
  - Limitations sur les API

### 2. Probl√®mes d'Architecture et d'Infrastructure
- **Environnement Local vs Databricks**
  - Incompatibilit√©s de versions Spark
  - Conflits de d√©pendances Java
  - Probl√®mes de configuration des clusters
  - Red√©marrages fr√©quents des clusters Databricks

- **Stack Technique**
  - Migration complexe depuis n8n/Segment/BigQuery
  - Double destination (Amplitude + Databricks)
  - Synchronisation multi-sources complexe
  - Gestion des formats de donn√©es h√©t√©rog√®nes

### 3. Probl√®mes de D√©veloppement
- **Organisation du Code**
  - Structure de projet d√©sorganis√©e
  - Tests dispers√©s et non standardis√©s
  - Documentation fragment√©e
  - Manque de coh√©rence dans les nomenclatures

- **Gestion des Donn√©es**
  - Validation des donn√©es incompl√®te
  - Probl√®mes de mapping des champs
  - Gestion des doublons complexe
  - Sch√©mas dynamiques difficiles √† maintenir

### 4. Probl√®mes de Performance et Monitoring
- **Performances**
  - Temps de traitement non optimis√©s
  - Latence webhook non mesur√©e
  - Probl√®mes de scalabilit√©
  - Gestion des lots inefficace

- **Monitoring**
  - Absence de m√©triques cl√©s
  - Pas de tableaux de bord de suivi
  - Alerting non configur√©
  - Logs incomplets ou inaccessibles

### 5. Probl√®mes de Gestion de Projet
- **Planning**
  - Retards significatifs sur le planning initial
  - D√©pendances bloquantes non identifi√©es
  - Estimation incorrecte des temps de d√©veloppement
  - Impact des probl√®mes d'autorisation sur les d√©lais

- **Communication**
  - Difficult√©s de coordination avec les √©quipes techniques
  - Probl√®mes d'escalade des incidents
  - Documentation insuffisante pour les √©quipes
  - Manque de visibilit√© sur l'avancement

### Impact sur le Projet
- **D√©lais**
  - Retard sur l'import initial des donn√©es
  - Blocage sur les d√©veloppements critiques
  - Report des phases de test
  - Ralentissement g√©n√©ral du projet

- **Qualit√©**
  - Risques sur l'int√©grit√© des donn√©es
  - Tests incomplets
  - Documentation partielle
  - Dette technique croissante
</details>

<details>
<summary> üéØ Plan d'Action Imm√©diat</summary>

### Phase 1 : R√©solution des Blocages (48h)
1. **Gestion des Autorisations** (Urgent)
   - [ ] Inventaire des acc√®s manquants par plateforme
     - Databricks : cr√©ation clusters, acc√®s DB
     - Azure : acc√®s logs, configuration webhooks
     - Salesforce : permissions API
     - Amplitude : droits d'administration
   - [ ] Escalade aux √©quipes concern√©es
   - [ ] Suivi des demandes d'acc√®s
   - [ ] Documentation des acc√®s obtenus

2. **Stabilisation Environnement Local** (Prioritaire)
   - [ ] Gestion des d√©pendances
     - Versions Spark compatibles
     - Configuration Java
     - Requirements.txt √† jour
   - [ ] Tests de compatibilit√©
     - Validation locale
     - Tests sur Databricks
     - V√©rification des connexions

3. **R√©organisation du Code** (Important)
   - [ ] Structure du projet
     - S√©paration claire webhook/salesforce
     - Organisation des tests
     - Centralisation des configurations
   - [ ] Documentation
     - README par composant
     - Guide de d√©ploiement
     - ProcÔøΩÔøΩdures de test

### Phase 2 : D√©veloppement S√©curis√© (72h)
1. **Mise en Place Tests**
   - [ ] Tests unitaires de base
     - Validation payload
     - Transformation donn√©es
     - Gestion erreurs
   - [ ] Tests d'int√©gration
     - Connexion Databricks
     - Envoi Amplitude
     - Webhooks Azure

2. **S√©curisation Donn√©es**
   - [ ] Validation donn√©es
     - Sch√©mas obligatoires
     - Formats attendus
     - Gestion doublons
   - [ ] Monitoring
     - Logs d√©taill√©s
     - M√©triques de base
     - Alertes critiques

3. **Optimisation Performance**
   - [ ] Traitement par lots
     - Taille optimale
     - Gestion m√©moire
     - Parall√©lisation
   - [ ] Gestion erreurs
     - Retry pattern
     - Circuit breaker
     - Logging avanc√©

### M√©triques de Suivi
- **Crit√®res de Succ√®s**
  - Environnement local stable et document√©
  - Tests de base fonctionnels
  - Acc√®s et permissions r√©solus
  - Premiers imports r√©ussis

- **Points de Contr√¥le**
  - Validation quotidienne des acc√®s
  - Tests automatis√©s
  - M√©triques de performance
  - Documentation √† jour

### Communication
- Daily avec √©quipe technique
- Points hebdomadaires stakeholders
- Documentation des blocages
- Suivi des escalades

### Livrables Attendus
1. **48h**
   - Inventaire complet des acc√®s
   - Environnement local stable
   - Structure projet claire

2. **72h**
   - Tests de base fonctionnels
   - Premier import test r√©ussi
   - Documentation technique initiale
</details>

<details>
<summary> üìã T√¢ches en Cours</summary>

### 1. Webhook Amplitude ‚Üí Databricks (En Review)
- [x] Cr√©ation script Azure Function
  - Endpoint webhook fonctionnel
  - Structure de base en place
  - Tests initiaux valid√©s
- [x] Configuration API Databricks
  - Connexion √©tablie
  - Param√®tres de base configur√©s
- [x] Validation donn√©es
  - Format payload v√©rifi√©
  - Sch√©mas d√©finis
- [ ] Gestion des erreurs (Bloqu√©)
  - Acc√®s logs manquant
  - Monitoring √† configurer
  - Alertes √† mettre en place

### 2. Tables et Donn√©es (En Cours)
- [ ] Tables Amplitude
  - [x] Identification des types de donn√©es
  - [ ] Tables temporaires en cr√©ation
  - [ ] Tables finales en pr√©paration
  - [ ] Sch√©mas en cours de d√©finition
  - [ ] Tests d'insertion √† faire

- [ ] Organisation des Donn√©es
  - [x] Scripts de base √©crits
  - [ ] Jobs p√©riodiques en attente
  - [ ] Tests d'int√©grit√© √† impl√©menter
  - [ ] Alertes √† configurer

### 3. Int√©grations Sources (Mixte)
#### Salesforce (En R√©vision)
- [x] Script de r√©cup√©ration
  - [x] Contacts
  - [x] Leads
  - [x] Opportunit√©s
- [x] Planification (5min)
- [ ] Double destination
  - [ ] Envoi Amplitude (Probl√®mes)
  - [ ] Stockage Databricks (√Ä valider)

#### Probl√®mes Identifi√©s
- Format des √©v√©nements non conforme aux sp√©cifications Amplitude
- Probl√®mes de performance sur les requ√™tes Salesforce
- Gestion des erreurs insuffisante
- Monitoring incomplet des envois

#### Actions Correctives
- [ ] R√©vision du format des √©v√©nements
  - [ ] Structure contact
  - [ ] Structure identify
  - [ ] Validation JSON
- [ ] Optimisation des requ√™tes
  - [ ] Limitation des champs
  - [ ] Gestion du rate limiting
  - [ ] Batch processing
- [ ] Am√©lioration monitoring
  - [ ] Logs d√©taill√©s
  - [ ] M√©triques de performance
  - [ ] Alertes en cas d'√©chec

#### Prochaines √âtapes
1. Correction du format des √©v√©nements
2. Tests avec petit volume (100 contacts)
3. Validation compl√®te des donn√©es
4. D√©ploiement progressif

#### Drift (En Cours)
- [ ] R√©cup√©ration √©v√©nements
  - [ ] Analyse des types d'√©v√©nements
  - [ ] Format de donn√©es d√©fini
  - [ ] Script de r√©cup√©ration en cours
  - [ ] Tests unitaires √† faire

#### Synchronisation
- [ ] Configuration Amplitude
- [ ] Tests connexion

### 4. Migration n8n (En Cours)
- [ ] Analyse des workflows
  - [x] Identification des scripts
  - [ ] Documentation des flux
  - [ ] Points d'int√©gration
- [ ] Conversion
  - [ ] Scripts Python
  - [ ] Tests unitaires
  - [ ] Validation fonctionnelle

### 5. Infrastructure (En Cours)
- [ ] Tests et Validation
  - [ ] Tests int√©gration
  - [ ] Tests performance
  - [ ] Tests charge
- [ ] Monitoring
  - [ ] Dashboards
  - [ ] Alertes
  - [ ] Logs

### Points de Blocage Actuels
1. **Autorisations** (Critique)
   - Cr√©ation clusters Databricks
   - Acc√®s logs Azure
   - Configuration compl√®te Amplitude

2. **Environnement** (Important)
   - Incompatibilit√©s versions
   - Configuration Spark
   - Stabilit√© clusters

3. **Tests** (√Ä D√©marrer)
   - Framework √† mettre en place
   - Environnement de test √† configurer
   - Donn√©es de test √† pr√©parer

### Prochaines Actions (24-48h)
1. **Priorit√© 1**
   - R√©solution acc√®s Databricks
   - Stabilisation environnement local
   - Tests basiques webhook

2. **Priorit√© 2**
   - Finalisation tables Amplitude
   - Tests int√©gration Drift
   - Documentation technique

### M√©triques Actuelles
- **Webhook** : 80% compl√©t√©
- **Tables** : 40% compl√©t√©
- **Int√©grations** : 60% compl√©t√©
- **Tests** : 20% compl√©t√©
</details>

<details>
<summary> üîÑ Int√©grations en Attente</summary>

### 1. Drift ‚Üí Amplitude (En Cours)
#### √âtat Actuel
- [ ] R√©cup√©ration √©v√©nements
  - [ ] Analyse des types d'√©v√©nements
  - [ ] Format de donn√©es d√©fini
  - [ ] Script de r√©cup√©ration en cours
  - [ ] Tests unitaires √† faire

#### Blocages
- Acc√®s API Drift incomplet
- Format des donn√©es √† valider
- Tests environnement √† configurer

#### Prochaines √âtapes
- Finalisation script r√©cup√©ration
- Tests avec donn√©es r√©elles
- Documentation technique

### 2. Salesforce ‚Üí Amplitude (En R√©vision)
#### √âtat Actuel
- [x] Script de r√©cup√©ration
  - [x] Contacts
  - [x] Leads
  - [x] Opportunit√©s
- [x] Planification (5min)
- [ ] Double destination
  - [ ] Envoi Amplitude (Probl√®mes)
  - [ ] Stockage Databricks (√Ä valider)

#### Probl√®mes Identifi√©s
- Format des √©v√©nements non conforme aux sp√©cifications Amplitude
- Probl√®mes de performance sur les requ√™tes Salesforce
- Gestion des erreurs insuffisante
- Monitoring incomplet des envois

#### Actions Correctives
- [ ] R√©vision du format des √©v√©nements
  - [ ] Structure contact
  - [ ] Structure identify
  - [ ] Validation JSON
- [ ] Optimisation des requ√™tes
  - [ ] Limitation des champs
  - [ ] Gestion du rate limiting
  - [ ] Batch processing
- [ ] Am√©lioration monitoring
  - [ ] Logs d√©taill√©s
  - [ ] M√©triques de performance
  - [ ] Alertes en cas d'√©chec

#### Prochaines √âtapes
1. Correction du format des √©v√©nements
2. Tests avec petit volume (100 contacts)
3. Validation compl√®te des donn√©es
4. D√©ploiement progressif

### 3. BigQuery ‚Üí Amplitude/Databricks (En Attente)
#### √Ä Faire
- [ ] Export donn√©es historiques
  - [ ] Analyse volum√©trie
  - [ ] Script d'export
  - [ ] Validation donn√©es
- [ ] Migration
  - [ ] Transformation donn√©es
  - [ ] Import Amplitude
  - [ ] V√©rification int√©grit√©

#### Pr√©requis
- Acc√®s BigQuery √† configurer
- Format de mapping √† d√©finir
- Environnement de test √† pr√©parer

### 4. Plan de Tracking ‚Üí Amplitude (Bloqu√©)
#### √âtat Actuel
- [ ] Analyse existant
  - [ ] Scripts actuels
  - [ ] Points de tracking
  - [ ] Format donn√©es
- [ ] Migration
  - [ ] Nouveau format
  - [ ] Tests parall√®les
  - [ ] Validation donn√©es

#### Blocages
- Documentation incompl√®te
- Acc√®s configurations actuelles
- Environnement de test

### 5. Migration n8n ‚Üí Databricks (En Cours)
#### En Cours
- [ ] Analyse des workflows
  - [x] Identification des scripts
  - [ ] Documentation des flux
  - [ ] Points d'int√©gration
- [ ] Conversion
  - [ ] Scripts Python
  - [ ] Tests unitaires
  - [ ] Validation fonctionnelle

#### Risques Identifi√©s
- Complexit√© des workflows
- D√©pendances multiples
- Tests incomplets

### Points de Vigilance G√©n√©raux
1. **Donn√©es**
   - Validation des formats
   - Gestion des doublons
   - Int√©grit√© des donn√©es

2. **Performance**
   - Temps de traitement
   - Utilisation ressources
   - Gestion des erreurs

3. **Monitoring**
   - Alertes en place
   - Logs accessibles
   - Tableaux de bord

### Prochaines Actions Prioritaires
1. **Imm√©diat (24h)**
   - Finalisation Drift
   - Tests BigQuery
   - Documentation workflows

2. **Court Terme (72h)**
   - Migration plan de tracking
   - Validation compl√®te Salesforce
   - Tests d'int√©gration
</details>

<details>
<summary>‚ö†Ô∏è Points de Vigilance Critiques</summary>

### 1. Probl√®mes d'Autorisation (URGENT)
- **Databricks**
  - [ ] Cr√©ation de clusters bloqu√©e
  - [ ] Acc√®s limit√© aux notebooks
  - [ ] Permissions DB incompl√®tes
  - [ ] Configuration des jobs restreinte

- **Azure**
  - [ ] Logs inaccessibles
  - [ ] Configuration webhook limit√©e
  - [ ] Monitoring incomplet
  - [ ] Gestion des erreurs impossible

- **Amplitude & Salesforce**
  - [ ] Tokens d'authentification √† s√©curiser
  - [ ] Permissions API √† compl√©ter
  - [ ] Webhooks √† configurer
  - [ ] Rate limiting √† g√©rer

### 2. Environnement de D√©veloppement (CRITIQUE)
- **Incompatibilit√©s**
  - [ ] Versions Spark local/Databricks
  - [ ] D√©pendances Java
  - [ ] Configurations Python
  - [ ] Packages syst√®me

- **Stabilit√©**
  - [ ] Red√©marrages fr√©quents des clusters
  - [ ] Connexions instables
  - [ ] Pertes de session
  - [ ] Timeouts fr√©quents

### 3. Organisation du Code (IMPORTANT)
- **Structure**
  - [ ] R√©organiser les fichiers Python
  - [ ] Centraliser les configurations
  - [ ] Standardiser les logs
  - [ ] Nettoyer les tests

- **Documentation**
  - [ ] Mise √† jour des README
  - [ ] Documentation des API
  - [ ] Guides de d√©ploiement
  - [ ] Proc√©dures de test

### 4. Performance et Donn√©es (CRITIQUE)
- **Validation**
  - [ ] Format des √©v√©nements
  - [ ] Champs obligatoires
  - [ ] Gestion des doublons
  - [ ] Int√©grit√© des donn√©es

- **Monitoring**
  - [ ] Temps de traitement
  - [ ] Taux d'erreur
  - [ ] Utilisation ressources
  - [ ] Alertes

### Actions Prioritaires (24-48h)
1. **Autorisations (URGENT)**
   - Escalade probl√®mes d'acc√®s
   - Documentation des besoins
   - Tests de validation
   - Mise en place workarounds

2. **Environnement (CRITIQUE)**
   - Standardisation configuration
   - Tests de compatibilit√©
   - Documentation d√©ploiement
   - Proc√©dures de recovery

3. **Code (IMPORTANT)**
   - Restructuration projet
   - Nettoyage d√©pendances
   - Mise √† jour documentation
   - Organisation tests

### M√©triques √† Surveiller
- **Performance**
  - Temps traitement < 2min/1000 records
  - Latence webhook < 1s
  - CPU cluster < 80%
  - M√©moire < 70%

- **Qualit√©**
  - Taux erreur < 0.1%
  - Couverture tests > 80%
  - Doublons = 0%
  - Data loss = 0%


</details>

<details>
<summary>üí∞ Budget et Facturation</summary>

### Vue d'Ensemble Financi√®re
- **Budget Initial** : 21 375,00 ‚Ç¨ HT
- **Acompte Novade (50%)** : 10 687,50 ‚Ç¨ HT
- **Montant Re√ßu par Thomas** : 4 200,00 ‚Ç¨ HT (1 800 non r√©gl√©)
- **Reste √† Facturer** : 10 687,50 ‚Ç¨ HT
- **Marge Tyrscale** : 7 125,00 ‚Ç¨ HT

### R√©partition Initiale
- **Jours Pr√©vus** : 28,5 jours
- **Gestion de Projet** : 4,5 jours (non consomm√©s)
- **D√©veloppement** : 24 jours (consomm√©s ++)

### √âtat Actuel
- **Complexit√© Additionnelle**
  - Probl√®mes d'autorisations multiples
  - Architecture technique plus complexe que pr√©vue
  - Int√©grations suppl√©mentaires n√©cessaires
  - Environnement de d√©veloppement complexe

### Proposition d'Ajustement
- **Enveloppe Suppl√©mentaire** : 5 000,00 ‚Ç¨ HT
  - Livrable √† la finalisation compl√®te du projet
  - Justifi√© par la complexit√© technique impr√©vue
  - Couvre les d√©veloppements additionnels n√©cessaires

### Justification
1. **Complexit√© Technique**
   - Migration multi-plateformes complexe
   - Probl√®mes d'autorisations non anticip√©s
   - Architecture technique plus sophistiqu√©e

2. **Travail Suppl√©mentaire**
   - D√©veloppement d'environnement local
   - Gestion des incompatibilit√©s
   - Tests et validations additionnels
   - Documentation extensive

3. **Reconnaissance Client**
   - Novade conscient des probl√®mes d'autorisation
   - Impact sur le planning initial
   - Complexit√© technique reconnue

### Options de Financement
1. **Solution Propos√©e**
   - Enveloppe suppl√©mentaire : 5 000,00 ‚Ç¨ HT
   - Paiement √† la livraison finale
   - Garantie de finalisation compl√®te

2. **Alternative**
   - Utilisation partielle de la marge Tyrscale
   - Uitiliser les jours de gestion de projet non consom√©
   - Maintien du budget initial
   - Ajustement du p√©rim√®tre

### √âtat des Paiements
1. **D√©j√† Re√ßu**
   - Acompte Novade : 10 687,50 ‚Ç¨ HT
   - Acompte Thomas : 6 000,00 ‚Ç¨ HT - environs 2000 euros non r√©gl√©
     

2. **√Ä Venir**
   - Solde Novade : 10 687,50 ‚Ç¨ HT
   - Bonus finalisation (si accept√©) : 5 000,00 ‚Ç¨ HT

### Points de Discussion
- Reconnaissance de la complexit√© technique
- Validation de l'enveloppe suppl√©mentaire
- Planning de facturation ajust√©
- Garanties de livraison
</details>
